{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload all src modules every time before executing the Python code typed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cld3\n",
    "import pycld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"ola k pasa tio\"\n",
    "print(pycld2.detect(test_str))\n",
    "print(cld3.get_language(test_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from cld2: (isReliable, textBytesFound, ((language, language code, proba, score), (...), ...)\n",
    "\n",
    "is_reliable: True if proba >0.5 for bosnian and croatian, >0.7 otherwise (see https://github.com/bsolomon1124/pycld3/blob/master/src/nnet_language_identifier.cc#L100). proportion is proportion of bytes wchih are assigned to the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "import os\n",
    "import json\n",
    "import cProfile\n",
    "import pandas as pd\n",
    "import geopandas as geopd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import src.utils.geometry as geo\n",
    "import src.data.shp_extract as shp_extract\n",
    "import src.data.tweets_cells_counts as tweets_counts\n",
    "import src.visualization.grid_viz as grid_viz\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "latlon_proj = 'epsg:4326'\n",
    "xy_proj = 'epsg:3857'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read remote json file and put chunks as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_username = os.environ['IFISC_USERNAME']\n",
    "ssh_domain = os.environ['IFISC_DOMAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh key needs to be stored on computer, here I had it in /home/.ssh/id_rsa.pub\n",
    "with paramiko.client.SSHClient() as ssh_client:\n",
    "    ssh_client.load_system_host_keys()\n",
    "    ssh_client.connect(ssh_domain, username=ssh_username)\n",
    "    sftp_client = ssh_client.open_sftp()\n",
    "    path = '/data/social/twitter/europe/201701_with_place/tweets_europe_201701_place.json'\n",
    "    with sftp_client.file(path, mode='r') as f:\n",
    "        chunks = pd.read_json(f, lines=True, chunksize = 100)\n",
    "        # chunks is an iteator: elements (which are data frames) can only be accessed \n",
    "        # in for loop or with native method next, it's not indexed.\n",
    "        df = next(chunks)\n",
    "    #     print(chunks.__next__())\n",
    "    #     for df in chunks:\n",
    "    #         df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try cld on these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve relevant cities' shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Murica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_proj = 'epsg:4326'\n",
    "xy_proj = 'epsg:3857'\n",
    "external_data_dir = '../data/external/'\n",
    "american_areas_data_file = os.path.join(external_data_dir, 'cbsa-est2017-alldata.csv')\n",
    "shapefile_name = 'cb_2016_us_cbsa_500k'\n",
    "shapefile_path = os.path.join(external_data_dir, shapefile_name, shapefile_name+'.shp')\n",
    "min_pop = 1400000\n",
    "init_cols = ['CBSA', 'LSAD', 'CENSUS2010POP', 'NAME']\n",
    "data_id_col = 'CBSA'\n",
    "shp_id_col = 'CBSAFP'\n",
    "msa = (\"Micropolitan Statistical Area\", \"Metropolitan Statistical Area\")\n",
    "filters = [lambda df: df['CENSUS2010POP'] > min_pop, lambda df: df['LSAD'].isin(msa)]\n",
    "# 2062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_area_df = shp_extract.get_cities_geometry(american_areas_data_file, shapefile_path, \n",
    "        filters, init_cols, data_id_col, shp_id_col, final_cols=['CBSA', 'NAME'], csv_engine='python')\n",
    "final_area_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_proj = 'epsg:4326'\n",
    "xy_proj = 'epsg:3857'\n",
    "external_data_dir = '../data/external'\n",
    "spanish_areas_data_file = os.path.join(external_data_dir, 'Poblacion_total_por_municipios._Padron_2015.csv')\n",
    "shapefile_name = 'Municipios_IGN'\n",
    "shapefile_path = os.path.join(external_data_dir, shapefile_name, shapefile_name+'.shp')\n",
    "min_pop = 500000\n",
    "init_cols = ['Codigo', 'Texto', 'Poblacion']\n",
    "data_id_col = 'Codigo'\n",
    "shp_id_col = 'CODIGOINE'\n",
    "filters = [lambda df: df['Poblacion'] > min_pop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain_area_df = shp_extract.get_cities_geometry(spanish_areas_data_file, shapefile_path, \n",
    "        filters, init_cols, data_id_col, shp_id_col)\n",
    "spain_area_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcelona_mask = spain_area_df['Texto']=='Barcelona'\n",
    "# barcelona_id = np.where(barcelona_mask)[0][0]\n",
    "barcelona_shape_df = spain_area_df.loc[barcelona_mask]\n",
    "# barcelona_shape = spain_area_df.loc[barcelona_id, 'geometry']\n",
    "cell_size = 1000\n",
    "cells_df, cells_in_bcn_df = geo.create_grid(barcelona_shape_df, 1000, latlon_proj, xy_proj, intersect=True)\n",
    "print(cells_df.info())\n",
    "print(cells_in_bcn_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPolygon\n",
    "a=MultiPolygon([cell[0] for cell in cells_df.values])\n",
    "list(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small example with the first few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = '../data/raw/'\n",
    "with open(raw_data_dir+'geo_unique_Barcelona_2014_2017.json') as f:\n",
    "    # file is a collection of json objects which are each on their own line,\n",
    "    # hence lines=True, and we read only a certain number of lines because of\n",
    "    # its size, and that is chunksize.\n",
    "    chunks = pd.read_json(f, lines=True, chunksize=100)\n",
    "    tweets_df = next(chunks)\n",
    "geometry = tweets_df['coordinates'].apply(lambda x: Point(x))\n",
    "crs = {'init': latlon_proj}\n",
    "tweets_gdf = geopd.GeoDataFrame(tweets_df, crs=crs, geometry=geometry)\n",
    "tweets_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_within_cells = geopd.sjoin(tweets_gdf, cells_in_bcn_df, op='within', rsuffix='cell')\n",
    "cell_tweet_counts = tweets_within_cells.groupby(['index_cell']).size()\n",
    "cell_tweet_counts.rename('count', inplace=True)\n",
    "cell_tweet_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_viz.plot_grid(cells_in_bcn_df, cell_tweet_counts, barcelona_shape_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cols = ['id', 'uid', 'created_at', 'coordinates']\n",
    "raw_data_dir = '../data/raw/'\n",
    "tweet_data_file = 'geo_unique_Barcelona_2014_2017.json'\n",
    "tweet_file_path = os.path.join(raw_data_dir, tweet_data_file)\n",
    "tweet_cols = ['id', 'uid', 'created_at', 'coordinates']\n",
    "dtype_dict = {'id': 'int', 'uid':'int', 'created_at': 'datetime64[s]', 'coordinates':'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_tweet_counts = tweets_counts.get_counts(tweet_file_path, cells_in_bcn_df, dtype_dict=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 243 sec\n",
    "cProfile.run(\"tweets_counts.get_counts(('{}', {}, dtype_dict={})\".format(\n",
    "    tweet_file_path, 'cells_in_bcn_df', 'dtype_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 375 sec\n",
    "cProfile.run(\"tweets_counts.get_counts_primitive('{}', {}, {})\".format(tweet_file_path, 'cells_in_bcn_df', 'tweet_cols'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_viz.plot_grid(cells_in_bcn_df, cell_tweet_counts, barcelona_shape_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
